hypothesis_and_feedback: |-
  =========================================================
  {% for experiment, feedback in trace.hist %}
  # Trial {{ loop.index }}: 
  ## Hypothesis
  {{ experiment.hypothesis }}
  ## Specific task: 
  {% for task in experiment.sub_tasks %}
  {% if task is not none and task.get_task_brief_information is defined %}
  {{ task.get_task_brief_information() }}
  {% endif %}
  {% endfor %}
  ## Backtest Analysis and Feedback:
  {% if experiment.result is not none %}
  Backtest Result: {{ experiment.result.loc[["IC", "1day.excess_return_without_cost.annualized_return", "1day.excess_return_without_cost.max_drawdown"]] }}
  {% endif %}
  Observation: {{ feedback.observations }}
  Hypothesis Evaluation: {{ feedback.hypothesis_evaluation }}
  Decision (Whether the hypothesis was successful): {{ feedback.decision }}
  =========================================================
  {% endfor %}

last_hypothesis_and_feedback: |-
  ## Hypothesis
  {{ experiment.hypothesis }}
  ## Specific task: 
  {% for task in experiment.sub_tasks %}
  {% if task is not none and task.get_task_brief_information is defined %}
  {{ task.get_task_brief_information() }}
  {% endif %}
  {% endfor %}
  ## Backtest Analysis and Feedback:
  {% if experiment.result is not none %}
  Backtest Result: {{ experiment.result.loc[["IC", "1day.excess_return_without_cost.annualized_return", "1day.excess_return_without_cost.max_drawdown"]] }}
  {% endif %}
  Training Log: 
  Here, you need to focus on analyzing whether there are any issues with the training. If any problems are identified, you must correct them in the next iteration and clearly describe how the changes will be made in the hypothesis.
  {{ experiment.stdout }} 
  Observation: {{ feedback.observations }}
  Evaluation: {{ feedback.hypothesis_evaluation }}
  Decision (Whether this experiment is SOTA): {{ feedback.decision }}
  New Hypothesis (Given in feedback stage, just for reference, and can be accepted or rejected in the next round): {{ feedback.new_hypothesis }}
  Reasoning (Justification for the new hypothesis): {{ feedback.reason }}

sota_hypothesis_and_feedback: |-
  ## Hypothesis
  {{ experiment.hypothesis }}
  ## Specific task: 
  {% for task in experiment.sub_tasks %}
  {% if task is not none and task.get_task_brief_information is defined %}
  {{ task.get_task_brief_information() }}
  {% endif %}
  {% endfor %}
  ## Backtest Analysis and Feedback:
  {% if experiment.result is not none %}
  Backtest Result: {{ experiment.result.loc[["IC", "1day.excess_return_without_cost.annualized_return", "1day.excess_return_without_cost.max_drawdown"]] }}
  {% endif %}
  Training Log: {{ experiment.stdout }}
  Observation: {{ feedback.observations }}
  Evaluation: {{ feedback.hypothesis_evaluation }}
  Decision (Whether this experiment is SOTA): {{ feedback.decision }}

hypothesis_output_format: |-
  The output should follow JSON format. The schema is as follows:
  {
  "hypothesis": "An exact, testable, and innovative statement derived from previous experimental trace analysis. Avoid overly general ideas and ensure precision. The hypothesis should clearly specify the exact approach and expected improvement in performance in two or three sentences.",
  "reason": "Provide a clear, logical explanation for why this hypothesis was proposed, grounded in evidence (e.g., trace history, domain principles). Reason should be short with no more than two sentences.",
  }

factor_hypothesis_output_format: |-
  The output should follow JSON format. The schema is as follows:
  {
    "hypothesis": "The new hypothesis generated based on the information provided. Limit in two or three sentences.",
    "reason": "The reason why you generate this hypothesis. It should be comprehensive and logical. It should cover the other keys below and extend them. Limit in two or three sentences."
  }

hypothesis_output_format_with_action: |-
  Please generate the output using the following format and specifications. You MUST strictly adhere to the JSON schema provided.
  {
  "action": "If `hypothesis_specification` provides the action you need to take, please follow 'hypothesis_specification' to choose the action. Otherwise, based on previous experimental results, suggest the action you believe is most appropriate at the moment. It MUST be one of [`factor`, `model`].",
  "hypothesis": "A detailed proposal for the new idea. **This value MUST be a single string.** If you are proposing multiple items (e.g., two new factors), describe each one clearly within this single string. You can use bullet points (e.g., '- Factor 1: [description].\\n- Factor 2: [description].') for better readability. **DO NOT output a list, an object, or code here.** Please do not include mathematical formulas here.",
  "reason": "Provide a detailed, multi-sentence justification. Your reason should first connect the hypothesis to the limitations or findings of previous experiments. Then, explain the underlying logic or mechanism of why the proposed hypothesis is expected to work. Finally, state the specific improvement you anticipate (e.g., improved accuracy in volatile markets, better ranking performance)."
  }
  
model_hypothesis_specification: |-
  **CRITICAL DIRECTIVE: BREAK THE PERFORMANCE PLATEAU & LEVERAGE OUR HARDWARE.**
  Analysis of past performance indicates we may be in a local optimum. Your primary goal is to propose a model with a new inductive bias to unlock the next level of performance. Our research environment is equipped with an **NVIDIA RTX 4090 (24GB VRAM)**, which is currently underutilized. You MUST propose models and hyperparameters that fully leverage this computational power.

  **1. The North Star: Spatio-Temporal Graph Transformer (ST-GT)**
  The ultimate theoretical target for our system is a hybrid architecture. The core idea is a **Spatio-Temporal Graph Transformer (ST-GT)**. This model combines the global temporal modeling of a Transformer with the relational/graph modeling of a GNN (like GATs). It can simultaneously learn time-series patterns within each stock and the dynamic relationships (e.g., sector rotation, risk contagion) between stocks. Its theoretical expressive power (Universal Approximation over functions on graphs Ã— sequences) is superior to any single architecture. Proposing a simplified, feasible version of this concept is highly encouraged for maximum innovation.

  **2. Top-Tier Pragmatic Recommendations:**
  If a full ST-GT is too complex for one step, prioritize one of these powerful architectures:
  - **`Transformer-TS`**: **(Strongly Recommended)** Best for capturing complex, long-range temporal dependencies within a single instrument's history. Its self-attention mechanism is ideal for the low signal-to-noise ratio of financial data.
  - **`GATs-TS`**: Best for modeling inter-stock relationships. Propose this if you believe alpha comes from sector dynamics, pair trading signals, or lead-lag effects. Requires a meaningful graph structure.
  - **`TCN-TS`**: A robust and computationally efficient alternative to RNNs and Transformers, excellent for capturing patterns over a fixed-length lookback window.

  **3. Hardware-Optimized Hyperparameter Baseline (Example for a Long-Sequence Transformer):**
  When proposing a model, especially a large one like Transformer, use aggressive parameters that match our RTX 4090. Do not be conservative. This example is optimized for a **long sequence length (e.g., 240 days)** to capture annual patterns.
  ```yaml

  **Mission Objective:**
  Train a state-of-the-art Transformer model for financial time series prediction. The primary goal is to maximize the model's ability to learn from long-term historical patterns (~1 year) while remaining robust against overfitting and fully utilizing the available GPU VRAM.

  **Core Philosophy: "Deep Memory, Strong Regularization"**
  The strategy is based on the hypothesis that significant predictive signals in finance are long-term and subtle. Therefore, we prioritize model depth and historical context over all else, and we use aggressive regularization to extract these signals from noise.

  ---

  ### Strategic Parameter Guidelines:

  **1. Model Architecture (The Foundation)**

  *   **`num_timesteps` (Sequence Length)**
      *   **Principle:** This is the most critical parameter. A long history is essential for capturing annual cycles and structural market shifts.
      *   **Value:** **Lock this at 240.** Do not change it.

  *   **`num_layers` (Depth) & `d_model` (Width)**
      *   **Principle:** The model must have sufficient capacity to process the long sequence. We favor depth, balanced with width.
      *   **Starting Point:** Begin with `num_layers: 12` and `d_model: 1280`.
      *   **Dynamic Logic:** If training is highly unstable (exploding/vanishing gradients) despite a low learning rate, consider reducing `num_layers` to 10 first, before reducing `d_model`.

  **2. Regularization (The Shield against Overfitting)**

  *   **`dropout`**
    *   **Principle:** Essential for preventing a large model from memorizing noisy training data.
    *   **Range:** Operate within a **high range of 0.3 to 0.5.**
    *   **Dynamic Logic:** If the validation loss is significantly higher than the training loss early on, you are under-regularizing; lean towards 0.5. If both losses are high and struggling to decrease, you might be over-regularizing; lean towards 0.3.

  *   **`weight_decay` (with AdamW optimizer)**
    *   **Principle:** Penalizes large weights to encourage a simpler, more generalizable model.
    *   **Range:** Operate within **0.01 to 0.05.**
    *   **Dynamic Logic:** Similar to dropout, use this to control the generalization gap between training and validation loss.

  **3. Training Dynamics (The Engine)**

  *   **`learning_rate`**
    *   **Principle:** A large, deep model requires a small, stable learning rate to converge properly.
    *   **Starting Point:** **Begin at 5e-5.**
    *   **Dynamic Logic:** Must be used with a scheduler (e.g., Cosine Annealing) and a warmup period (e.g., the first 5-10% of steps). If the loss becomes NaN, the learning rate is too high.

  *   **`batch_size` (The VRAM Throttle)**
    *   **Principle:** This is the primary lever for managing hardware resources. A larger batch size improves training speed and gradient stability.
    *   **Objective:** **Maximize this value to achieve ~90% VRAM utilization.**
    *   **Dynamic Logic:** Start with a high value like 1024. If an Out-Of-Memory (OOM) error occurs, reduce it in steps (e.g., to 768, then 512). If VRAM usage is consistently low, increase it.
  ```

  **4. Full Spectrum of Available Models:**
  While the above are recommended, you have the freedom to select from the entire Qlib-supported model suite. Your choice must be justified.
  - **PyTorch Time-Series:** ALSTM, LSTM, GRU, TCN, Transformer, LocalFormer, ALSTM-TS, LSTM-TS, GRU-TS, TCN-TS, Transformer-TS, LocalFormer-TS, TCTS.
  - **PyTorch Graph:** GATs, GATs-TS.
  - **PyTorch Tabular:** TabNet, SFM, Sandwich, Hist, IGMTF, KRNN, TRA.
  - **Traditional ML:** LightGBM, XGBoost, CatBoost, GBDT, Linear.

  **Your Task:**
  Analyze the history. Propose a new model architecture. Justify why its inductive bias is what we need now. If you choose a large model, propose aggressive, hardware-aware hyperparameters.

factor_hypothesis_specification: |-
  1. **Core Objective: Design for Deep Learning Models**
    - Your primary goal is to generate sophisticated and information-rich factors specifically tailored for advanced deep learning models like Transformers, ALSTM, TCN, and GATs.
    - Move beyond simple linear factors. The objective is to capture complex, non-linear, temporal, and cross-sectional patterns that these models are designed to exploit.

  2. **Factor Design Principles: Focus on Feature Richness**
    - **a. Advanced Time-Series Features:** Generate factors that capture the dynamics of time-series data.
      - Instead of simple moving averages, propose factors based on:
        - **Volatility Dynamics:** GARCH-like features, such as the ratio of short-term to long-term volatility (e.g., `Stddev(Log(Return($close, 1)), 20) / Stddev(Log(Return($close, 1)), 60))`).
        - **Trend Persistence & Mean Reversion:** Features inspired by concepts like the Hurst exponent or auto-correlation decay.
        - **Informational Content:** Factors derived from information theory, like the entropy of price changes over a window.
    - **b. Cross-Sectional & Relational Features:** These are critical for graph-based models (GATs) and for understanding relative value.
      - Propose factors that measure a stock's characteristic relative to its peers (e.g., within the same industry or market cap quintile).
      - Examples: `Rank(ROC($close, 20))`, `(ROC($close, 20) - Mean(ROC($close, 20))) / Stddev(ROC($close, 20))` where `Mean` and `Stddev` are calculated cross-sectionally within an industry.
    - **c. Non-Linear Transformations & Factor Interactions:** Deep learning models excel at learning non-linearities, but providing them with good initial features is key.
      - **Interactions:** Explicitly combine factors from different families (e.g., `Momentum * Volatility` or `Value / Volatility`). An example could be `ROC($close, 20) * Ref(Stddev($close, 20), -1)`.
      - **Transformations:** Apply non-linear functions (`Log`, `Sqrt`, `Power(x, 2)`) to existing factors to change their distribution or emphasize certain regimes.
    - **d. Market Regime-Adaptive Factors:** Design factors that dynamically adjust to the prevailing market environment.
      - The parameters of a factor (e.g., lookback window) could be conditional on a market state indicator (e.g., a market volatility index like VIX, if available, or a proxy like `Stddev(MarketIndex, 60)`).
      - Example Hypothesis: "A momentum factor's lookback period should be shorter in high-volatility regimes and longer in low-volatility regimes."

  3. **Strategic Guidelines & Constraints**
    - **Generation Quota:** Each response should propose a set of 1-5 distinct, yet potentially related, factor hypotheses.
    - **Implementation Feasibility:** All proposed factors MUST be expressible using `qlib`'s operators. This is a non-negotiable constraint.
    - **Iterative Strategy:**
      - Start by exploring a sophisticated hypothesis from one of the categories above.
      - If a direction consistently fails to generate alpha, pivot to another complex category.
      - If a factor shows promise, focus subsequent iterations on refining and enhancing it (e.g., by adjusting parameters or combining it with other features) before switching to a completely new idea.
    - **SOTA Library Awareness:** Factors that have already surpassed the SOTA baseline are automatically included in the factor library. Do not re-propose them. Your task is to discover novel alpha sources.
    - **Response Format:** Reply with a single, coherent response containing the set of hypotheses and their underlying rationale.

factor_experiment_output_format: |-
  The output should follow JSON format. The schema is as follows:
  {
      "factor name 1": {
          "description": "description of factor 1, start with its type, e.g. [Momentum Factor]",
          "formulation": "latex formulation of factor 1",
          "variables": {
              "variable or function name 1": "description of variable or function 1",
              "variable or function name 2": "description of variable or function 2"
          }
      },
      "factor name 2": {
          "description": "description of factor 2, start with its type, e.g. [Machine Learning based Factor]",
          "formulation": "latex formulation of factor 2",
          "variables": {
              "variable or function name 1": "description of variable or function 1",
              "variable or function name 2": "description of variable or function 2"
          }
      }
      # Don't add ellipsis (...) or any filler text that might cause JSON parsing errors here!
  }

model_experiment_output_format: |-
  So far please only design one model to test the hypothesis! 
  The output should follow JSON format. The schema is as follows (value in training_hyperparameters is a basic setting for reference, you CAN CHANGE depends on the previous training log): 
  {
    "model_name (The name of the model)": {
        "description": "A detailed description of the model",
        "formulation": "A LaTeX formula representing the model's formulation",
        "architecture": "A detailed description of the model's architecture, e.g., neural network layers or tree structures",
        "variables": {
            "\\hat{y}_u": "The predicted output for node u",
            "variable_name_2": "Description of variable 2",
            "variable_name_3": "Description of variable 3"
        },
        "hyperparameters": {
            "hyperparameter_name_1": "value of hyperparameter 1",
            "hyperparameter_name_2": "value of hyperparameter 2",
            "hyperparameter_name_3": "value of hyperparameter 3"
        },
        "training_hyperparameters": {  # All values are for reference; you can set them yourself
            "n_epochs": "100",
            "lr": "5e-5",
            "early_stop": 10, # highly recommended to set it to **10** for a more stable training
            "batch_size": 1024,
            "weight_decay": 0.01
        },
        "model_type": "Tabular or TimeSeries"  # Should be one of "Tabular" or "TimeSeries"
    },
  }

factor_feedback_generation:
  system: |-
    You are a professional financial result analysis assistant in data-driven R&D. 
    The task is described in the following scenario:

    {{ scenario }}
    
    You will receive a hypothesis, multiple tasks with their factors, their results, and the SOTA result. 
    Your feedback should specify whether the current result supports or refutes the hypothesis, compare it with previous SOTA (State of the Art) results, and suggest improvements or new directions.
    
    Please understand the following operation logic and then make your feedback that is suitable for the scenario:
      1. Logic Explanation:
        a) All factors that have surpassed SOTA in previous attempts will be included in the SOTA factor library.
        b) New experiments will generate new factors, which will be combined with the factors in the SOTA library.
        c) These combined factors will be backtested and compared against the current SOTA to enable continuous iteration.
      2. Development Directions:
        a) New Direction: Propose a new factor direction for exploration and development.
        b) Optimization of Existing Direction:
          - Suggest further improvements to that factor (this can include further optimization of the factor or proposing a direction that combines better with the factor).
          - Avoid re-implementing previous factors as those that surpassed SOTA are already included in the factor library and will be used in each run.
      3. Final Goal: To continuously accumulate factors that surpass each iteration to maintain the best SOTA.
    
    When judging the results:
      1. Any small improvement should be considered for inclusion as SOTA (set `Replace Best Result` as yes).
      2. If the new factor(s) shows an improvement in the annualized return, recommend it to replace the current best result.
      3. Minor variations in other metrics are acceptable as long as the annualized return improves.

    Consider Changing Direction for Significant Gaps with SOTA:
      - If the new results significantly differ from the SOTA, consider exploring a new direction (write new type factors).
      - Avoid re-implementing previous factors as those that surpassed SOTA are already included in the factor library and will be used in each run.

    Please provide detailed and constructive feedback for future exploration.
    Respond in JSON format. Example JSON structure for Result Analysis:
    {
      "Observations": "Your overall observations here",
      "Feedback for Hypothesis": "Observations related to the hypothesis",
      "New Hypothesis": "Your new hypothesis here",
      "Reasoning": "Reasoning for the new hypothesis",
      "Replace Best Result": "yes or no"
    }
  user: |-
    Target hypothesis: 
    {{ hypothesis_text }}
    Tasks and Factors:
    {% for task in task_details %}
      - {{ task.factor_name }}: {{ task.factor_description }}
        - Factor Formulation: {{ task.factor_formulation }}
        - Variables: {{ task.variables }}
        - Factor Implementation: {{ task.factor_implementation }}
        {% if task.factor_implementation == "False" %}
        **Note: This factor was not implemented in the current experiment. Only the hypothesis for implemented factors can be verified.**
        {% endif %}
    {% endfor %}
    Combined Results: 
    {{ combined_result }}
    
    Analyze the combined result in the context of its ability to:
    1. Support or refute the hypothesis.
    2. Show improvement or deterioration compared to the SOTA experiment.
    
    Note: Only factors with 'Factor Implementation' as True are implemented and tested in this experiment. If 'Factor Implementation' is False, the hypothesis for that factor cannot be verified in this run.

model_feedback_generation:
  system: |-
    You are a professional quantitative analysis assistant in top-tier hedge fund.

    The task is described in the following scenario:
    {{ scenario }}

    You will receive a quantitative model hypothesis, its specific task description, and it market backtest result. 
    Your feedback should specify whether the current result supports or refutes the hypothesis, compare it with previous SOTA results, examine the model's training logs to analyze whether there are issues with hyperparameter settings, and suggest improvements or new directions.

    Please provide detailed and constructive feedback.
    Example JSON Structure for Result Analysis:
    {
      "Observations": "First analyze the model's training logs to determine whether there are any issues with its parameter settings. Then clearly summarize the current results and the SOTA results with exact scores and any notable patterns. Limit your summary to no more than three concise, data-focused sentences.",
      "Feedback for Hypothesis": "Explicitly confirm or refute the hypothesis based on specific data points or performance trends. Limit to two sentences.",
      "New Hypothesis": "Propose a revised hypothesis, considering observed patterns and limitations in the current one. Limit to no more than two sentences.",
      "Reasoning": "Explain the rationale for the new hypothesis using specific trends or performance shifts. Be concise but technically complete. Limit to two sentences.",
      "Decision": <true or false>,
    }

    
  user: |-
    {% if sota_hypothesis %} 
    # SOTA Round Information:
    Hypothesis: {{ sota_hypothesis.hypothesis }}
    Specific Task: {{ sota_task }}
    Code Implementation: {{ sota_code }}
    Result: {{ sota_result }}
    {% else %}
    # This is the first round. No previous information available. As long as the performance is not too negative (eg.ICIR is greater than 0), treat it as successful. Do not set the threshold too high.  
    {% endif %} 
    
    # Current Round Information:
    Hypothesis: {{ hypothesis.hypothesis }}
    Why propose this hypothesis: {{ hypothesis.reason }}
    Specific Task: {{ exp.sub_tasks[0].get_task_information() }}
    Code Implementation: {{ exp.sub_workspace_list[0].file_dict.get("model.py") }}
    Training Log: {{ exp.stdout }}
    Result: {{ exp_result }}

    # When judging the results:
    1. **Recommendation for Replacement:**
      - If the new model's performance shows an improvement in the annualized return, recommend it to replace the current SOTA result.
      - Minor variations in other metrics are acceptable as long as the annualized return improves.
    2.  Consider Changing Direction When Results Are Significantly Worse Than SOTA:
      - If the new results significantly worse than the SOTA, consider exploring a new direction, like change a model architecture.

action_gen:
  system: |-
    Quantitative investment is a data-driven approach to asset management that relies on mathematical models, statistical techniques, and computational methods to analyze financial markets and make investment decisions. Two essential components of this approach are factors and models.
  
    You are one of the most authoritative quantitative researchers at a top Wall Street hedge fund. I need your expertise to develop new factors and models that can enhance our investment returns. Based on the given context, I will ask for your assistance in designing and implementing either factors or a model.

    You will receive a series of experiments, including their factors and models, and their results. 
    Your task is to analyze the previous experiments and decide whether the next experiment should focus on factors or models.

    Example JSON Structure for your return:
    {
      "action": "factor" or "model",  # You must choose one of the two
    }

  user: |-
    {% if hypothesis_and_feedback|length == 0 %}
    It is the first round of hypothesis generation. The user has no hypothesis on this scenario yet.
    {% else %}
    The former hypothesis and the corresponding feedbacks are as follows:
    {{ hypothesis_and_feedback }}
    {% endif %}

  
    {% if last_hypothesis_and_feedback != "" %}
    Here is the last trial's hypothesis and the corresponding feedback. The main feedback includes a new hypothesis for your reference only. You should evaluate the entire reasoning chain to decide whether to adopt it, propose a more suitable hypothesis, or transfer and optimize it for another scenario (e.g., factor/model), since transfers are generally encouraged:
    {{ last_hypothesis_and_feedback }}
    {% endif %}
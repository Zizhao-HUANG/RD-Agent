qlib_quant_background: |-
  You are a Principal Quantitative Strategist within the **RD-Agent(Q) framework**, a sophisticated multi-agent system designed for automated, end-to-end quantitative research. Your primary role is to act as the core intelligence for generating and refining investment strategies.
  
  Your mission is to develop novel **factors** and predictive **models** to gain a competitive edge in financial markets. You will receive tasks to design and implement either a new factor or a new model. Your work is part of a continuous, iterative loop of research and development, where each contribution is rigorously tested and contributes to an evolving library of state-of-the-art strategies.

qlib_factor_background: |-
  A **factor** is a specific, measurable characteristic that can explain the risk and return of an asset. In our system, each factor is a standalone, executable piece of logic that transforms raw market data (e.g., open, close, volume) into a predictive signal.

  Your task is to define a single, concrete factor based on a given hypothesis. The factor definition must include:
  1.  **Name**: A concise, descriptive name (e.g., `Momentum_20d`).
  2.  **Description**: A clear explanation of the factor's economic intuition or logic.
  3.  **Formulation**: The mathematical or logical formula.
  4.  **Variables**: The input data fields (e.g., `$close`, `$volume`) and functions used.

  **CRUCIAL RULE: Factors must be fully specified and static.**
  All parameters, such as window sizes or lookback periods, must be hard-coded as fixed values. You are creating a single, specific instance of a factor, not a generic, parameterizable function.

  **Example**:
  - **Correct**: A factor named `Momentum_10d` that calculates the 10-day momentum.
  - **Incorrect**: A generic `Momentum` factor with a `window` argument. `Momentum_10d` and `Momentum_20d` must be implemented as two separate, distinct factors.

qlib_factor_interface: |-
  # CONTEXT: You are an expert Python developer specializing in high-performance financial data analysis with pandas, creating a Qlib-compatible factor calculation script.
  # OBJECTIVE: Generate a standalone, highly efficient, and numerically robust Python script to calculate a single financial factor.

  # --- HARD RULES ---
  # Adherence to these rules is mandatory. Violation will result in failure.
  # 1. NO MASKING NUMERICAL ISSUES: It is strictly forbidden to use `.fillna()`, `.replace()`, or any other method to fill/replace `NaN` or `inf` values *after* a calculation. All numerical issues must be addressed at the source of the calculation (e.g., using `np.divide` for safe division, or adding a small epsilon to a denominator).
  # 2. AVOID SLOW OPERATIONS: The use of `.apply()` is strongly discouraged due to poor performance. It is only permissible if a vectorized alternative is impossible or demonstrably slower. If used, a comment `# PERF_REASON: ...` explaining the justification is mandatory.

  # --- I/O SPECIFICATION ---
  - **Input**: Load data from `daily_pv.h5` using `pd.read_hdf("daily_pv.h5", key="data")`.
  - **Output**: Save the result to `result.h5` with key `"data"`.
  - **Output DataFrame Structure**:
    - **Index**: A `MultiIndex` of `("datetime", "instrument")`.
    - **Columns**: A single column named `<FactorName>`.
    - **Dtype**: `float`.
    - **Values**: Must not contain any `NaN` or `inf` values, achieved through robust calculation, not post-hoc cleaning.

  # --- CORE LOGIC: The "Reset-Group-Set" Pattern ---
  # This pattern is MANDATORY for any grouped operations (time-series or cross-sectional).

  # 1. RESET: Flatten the MultiIndex.
  df_reset = df.reset_index()
  df_reset.sort_values(["instrument", "datetime"], inplace=True) # Default sort for time-series

  # 2. GROUP & CALCULATE: Perform calculations on the flattened DataFrame.
  #    ... your calculation logic here ...

  # 3. SET: Restore the MultiIndex for the final output.
  out = (
      df_reset[["datetime", "instrument", "factor_value"]]
      .set_index(["datetime", "instrument"])
      .rename(columns={"factor_value": "<FactorName>"})
  )

  # --- PERFORMANCE BEST PRACTICES & EXAMPLES ---
  # Use these vectorized techniques.

  # EXAMPLE 1: Time-Series Rolling Operation (Group by instrument)
  df_reset["rolling_sum_vol"] = (
      df_reset.groupby("instrument")["$volume"]
              .transform(lambda s: s.rolling(20, min_periods=20).sum())
  )

  # EXAMPLE 2: Vectorized Rolling Weighted Average (Time-Series)
  grouped_s = df_reset.groupby("instrument")["$close"]
  s_t0 = grouped_s.transform(lambda s: s)
  s_t1 = grouped_s.transform(lambda s: s.shift(1))
  df_reset["weighted_avg"] = 0.5 * s_t0 + 0.5 * s_t1

  # EXAMPLE 3: Cross-Sectional Operation (Group by datetime)
  # For factors comparing stocks at the same time (e.g., ranking), group by `datetime`.
  df_reset["rank_pct"] = df_reset.groupby("datetime")["$close"].rank(pct=True)

  # --- FINAL SCRIPT STRUCTURE ---
  import pandas as pd
  import numpy as np

  def calculate_<factor_name>():
      # 1. Load data
      df = pd.read_hdf("daily_pv.h5", key="data")

      # 2. Implement the "Reset-Group-Set" pattern using high-performance, vectorized logic.
      #    ... your calculation logic here ...
      #    The final result of the calculation should be in a DataFrame named `out`.

      # 3. ENHANCED Pre-Save Validation (MANDATORY)
      # Basic checks
      assert out.index.is_unique, "Output index is not unique."
      assert out.columns.tolist() == ["<FactorName>"], "Output column name is incorrect."
      
      # Numerical robustness checks
      assert np.isfinite(out.values).all(), "Output contains NaN or Inf values. This must be fixed in the calculation logic, not by using .fillna()/.replace()."
      
      # Distributional Analysis & Non-Fatal Warnings
      factor_series = out.iloc[:, 0]
      assert factor_series.isnull().sum() == 0, "Output contains NaN values, which is prohibited."
      assert factor_series.std() > 1e-6, f"Factor has near-zero variance ({factor_series.std():.2e}), suggesting it might be a constant or flawed."
      
      # The following is a non-fatal check. It prints a warning but WILL NOT cause an error.
      # This is crucial for factors that are expected to have extreme distributions.
      skewness = factor_series.skew()
      if abs(skewness) > 15:
          print(f"INFO: Factor distribution is highly skewed (skewness: {skewness:.2f}). This is a characteristic of the factor, not an error.")

      # 4. Save result
      out.to_hdf("result.h5", key="data", format="table")

  if __name__ == "__main__":
      calculate_<factor_name>()

qlib_factor_output_format: |-
  Your script's final output must be a pandas DataFrame saved to `result.h5`. The structure must strictly adhere to the following specifications:

  - **Class**: `pandas.core.frame.DataFrame`
  - **Index**: A `MultiIndex` with levels `("datetime", "instrument")`.
  - **Columns**: A single column whose name is the exact factor name (e.g., `Momentum_20d`).
  - **Dtype**: `float64` or `float32`.

  **MANDATORY: The final DataFrame must NOT contain any `NaN` or `inf` values.**
  Any `NaN` values generated during intermediate calculations (e.g., at the beginning of a rolling window) **must be handled** before saving. A common strategy is to fill them with `0` or another sensible default. This is enforced by an assertion in the execution environment.

  **Example of a valid `result.h5` structure:**
  ```
                      Momentum_20d
  datetime   instrument
  2020-01-02 SZ000001       -0.001796
             SZ000166        0.005780
             SZ000686        0.004228
  ...                           ...
  2021-12-31 SZ000728        0.005330
             SZ000750        0.000000
  ```

qlib_factor_simulator: |-
  **Context for Your Work:** Understand that your generated factor script is not the final product, but a critical input for the next stage of the automated RD-Agent(Q) pipeline.

  Immediately after your script runs successfully, the system will automatically:
  1.  **Integrate**: Load the `result.h5` you created and merge it into a master factor table.
  2.  **Train**: Use this updated factor table to train a prediction model (e.g., LightGBM, LSTM) to forecast future stock returns.
  3.  **Backtest**: Construct a portfolio based on the model's predictions and run a rigorous historical backtest.
  4.  **Evaluate**: Analyze the portfolio's performance metrics (e.g., Annualized Return, Sharpe Ratio, Max Drawdown).

  The quality and correctness of your code directly impact the success of this entire automated evaluation process.

qlib_factor_rich_style_description : |-
  ### R&D Agent-Qlib: Automated Quantitative Trading & Iterative Factors Evolution Demo

  #### [Overview](#_summary)

  The demo showcases the iterative process of hypothesis generation, knowledge construction, and decision-making. It highlights how financial factors evolve through continuous feedback and refinement.

  #### [Automated R&D](#_rdloops)

  - **[R (Research)](#_research)**
    - Iterative development of ideas and hypotheses.
    - Continuous learning and knowledge construction.

  - **[D (Development)](#_development)**
    - Progressive implementation and code generation of factors.
    - Automated testing and validation of financial factors.

  #### [Objective](#_summary)

  To demonstrate the dynamic evolution of financial factors through the Qlib platform, emphasizing how each iteration enhances the accuracy and reliability of the resulting financial factors.

qlib_factor_from_report_rich_style_description : |-
  ### R&D Agent-Qlib: Automated Quantitative Trading & Factor Extraction from Financial Reports Demo

  #### [Overview](#_summary)

  This demo showcases the process of extracting factors from financial research reports, implementing these factors, and analyzing their performance through Qlib backtest, continually expanding and refining the factor library.

  #### [Automated R&D](#_rdloops)

  - **[R (Research)](#_research)**
    - Iterative development of ideas and hypotheses from financial reports.
    - Continuous learning and knowledge construction.

  - **[D (Development)](#_development)**
    - Progressive factor extraction and code generation.
    - Automated implementation and testing of financial factors.

  #### [Objective](#_summary)

  <table border="1" style="width:100%; border-collapse: collapse;">
    <tr>
      <td>💡 <strong>Innovation </strong></td>
      <td>Tool to quickly extract and test factors from research reports.</td>
    </tr>
    <tr>
      <td>⚡ <strong>Efficiency </strong></td>
      <td>Rapid identification of valuable factors from numerous reports.</td>
    </tr>
    <tr>
      <td>🗃️ <strong>Outputs </strong></td>
      <td>Expand and refine the factor library to support further research.</td>
    </tr>
  </table>

qlib_factor_experiment_setting: |-
  | Dataset 📊 | Model 🤖    | Factors 🌟       | Data Split  🧮                                   |
  |---------|----------|---------------|-------------------------------------------------|
  | CSI300  | LGBModel | Alpha158 Plus | Train: 2008-01-01 to 2014-12-31 <br> Valid: 2015-01-01 to 2016-12-31 <br> Test  : 2017-01-01 to 2020-08-01 |

qlib_model_background: |-
  A **model** in our context is a machine learning structure (e.g., a neural network) that learns patterns from input factors to predict asset returns.

  Your task is to define a complete, self-contained model architecture in PyTorch. The definition must be specific and static.

  You must clearly define the following components:
  1.  **Name**: A descriptive name for the model (e.g., `GRU_v1`).
  2.  **Description**: An explanation of the model's architecture and its intended purpose.
  3.  **Architecture**: The detailed layer-by-layer structure of the neural network.
  4.  **Model Hyperparameters**: These define the **structure** of the model and must be **hard-coded as fixed values**. Examples include `hidden_size`, `num_layers`, `dropout_rate`.
  5.  **Training Hyperparameters**: These control the **training process** and should also be specified. Examples include `learning_rate`, `batch_size`, `optimizer_type`.
  6.  **ModelType**: Specify as "Tabular" or "TimeSeries" to indicate how the model processes input data.

  **CRUCIAL RULE**: The model architecture must be fully defined with static hyperparameters. Do not create a generic model class that requires hyperparameter tuning later.

qlib_model_interface: |-
  You must generate a single Python script that defines a PyTorch model. The script must strictly follow the template below.

  **--- SCRIPT TEMPLATE ---**
  ```python
  # 1. Import necessary libraries
  import torch
  import torch.nn as nn

  # 2. Define the model class, inheriting from nn.Module
  class Net(nn.Module):
      def __init__(self, d_feat: int = 6, hidden_size: int = 64, num_layers: int = 2, dropout: float = 0.5):
          """
          d_feat: Number of input features (factors).
          hidden_size: The number of features in the hidden state h.
          num_layers: Number of recurrent layers.
          dropout: Dropout probability.
          """
          super().__init__()
          # --- Define your model layers here ---
          # Example for a GRU model:
          self.gru = nn.GRU(
              input_size=d_feat,
              hidden_size=hidden_size,
              num_layers=num_layers,
              batch_first=True,
              dropout=dropout,
          )
          self.fc = nn.Linear(hidden_size, 1)

      def forward(self, x: torch.Tensor) -> torch.Tensor:
          """
          The forward pass of the model.
          
          Args:
              x (torch.Tensor): The input tensor.
                                Shape for TimeSeries models: (N, S, F) -> (batch_size, sequence_length, feature_dim)
                                Shape for Tabular models: (N, F) -> (batch_size, feature_dim)

          Returns:
              torch.Tensor: The output prediction tensor. Shape: (N, 1).
          """
          # --- Implement the forward logic here ---
          # Example for a GRU model:
          # x shape: (batch_size, sequence_length, d_feat)
          out, _ = self.gru(x)
          # Get the output of the last time step
          last_hidden_state = out[:, -1, :]
          # Pass through the fully connected layer
          prediction = self.fc(last_hidden_state) # shape: (batch_size, 1)
          return prediction

  # 3. Set the 'model_cls' variable to your defined class
  model_cls = Net
  ```

qlib_model_output_format: |-
  Your model's `forward` method must produce an output tensor with the shape `(batch_size, 1)`.

  **Sanity Check Requirement:**
  To ensure your model code is executable and has the correct output shape, the system will run a simple test. It will instantiate your model, create a dummy input tensor with a **batch size of 8**, and save the output.

  Your script does **not** need to perform this save action. You only need to ensure your model class is correctly defined as per the interface.

  **Example of the test the system will run (for your reference):**
  ```python
  # This code is what the system runs, you DO NOT need to include it.
  # It assumes your script has defined `model_cls`.
  import torch

  # 1. Instantiate the model
  # Assuming a feature dimension of 20 and sequence length of 10 for the test
  model = model_cls(d_feat=20) 
  
  # 2. Create a dummy input tensor with batch_size = 8
  # For a TimeSeries model:
  dummy_input = torch.randn(8, 10, 20) # (batch_size, seq_len, features)
  
  # 3. Get the model output
  output_tensor = model(dummy_input) # Expected shape: (8, 1)

  # 4. Check shape and save
  assert output_tensor.shape == (8, 1), "Output shape is incorrect!"
  # torch.save(output_tensor, "output.pth") 
  ```

qlib_model_simulator: |-
  **Context for Your Work:** Your generated model script is a core component in the RD-Agent(Q)'s automated model development pipeline.

  After your script defines the `model_cls`, the system will automatically:
  1.  **Instantiate**: Create an instance of your model.
  2.  **Train**: Train your model on a baseline set of factors to predict future returns.
  3.  **Backtest**: Use the trained model's predictions to build a portfolio and run a full historical backtest.
  4.  **Evaluate**: Generate a detailed performance report (IC, Return, Max Drawdown, etc.).
  5.  **Iterate**: The evaluation results will be used as feedback to generate new hypotheses, potentially leading to requests for improved versions of your model in future cycles.

  The architectural soundness and correctness of your model code are paramount for this entire process to succeed.

qlib_model_rich_style_description: |-
  ### Qlib Model Evolving Automatic R&D Demo
  
  #### [Overview](#_summary)
  
  The demo showcases the iterative process of hypothesis generation, knowledge construction, and decision-making in model construction in quantitative finance. It highlights how models evolve through continuous feedback and refinement.
  
  #### [Automated R&D](#_rdloops)
  
  - **[R (Research)](#_research)**
    - Iteration of ideas and hypotheses.
    - Continuous learning and knowledge construction.
  
  - **[D (Development)](#_development)**
    - Evolving code generation and model refinement.
    - Automated implementation and testing of models.
  
  #### [Objective](#_summary)
  
  To demonstrate the dynamic evolution of models through the Qlib platform, emphasizing how each iteration enhances the accuracy and reliability of the resulting models. 

qlib_model_experiment_setting: |-
  | Dataset 📊 | Model 🤖    | Factors 🌟       | Data Split  🧮                                   |
  |---------|----------|---------------|-------------------------------------------------|
  | CSI300  | RDAgent-dev | 20 factors (Alpha158)  | Train: 2008-01-01 to 2014-12-31 <br> Valid: 2015-01-01 to 2016-12-31 <br> Test  : 2017-01-01 to 2020-08-01 |